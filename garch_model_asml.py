# -*- coding: utf-8 -*-
"""garch model asml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b681qZSqxTCWbtzbOmtuuvb3pT3UF1gz
"""

!pip install arch

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from arch import arch_model
from sklearn.metrics import mean_squared_error, mean_absolute_error
from google.colab import files

# Configuration des graphiques
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

files.upload()

df = pd.read_excel('asml stock h.xlsx')

df['Dates'] = pd.to_datetime(df['Dates'], errors='coerce', dayfirst=True)
df.set_index('Dates', inplace=True)
df = df.sort_values(by='Dates', ascending=True)
df.head()

df['Returns'] = df['PX_LAST'].pct_change().dropna()
df = df.dropna()
df['Returns']=df['Returns']*100

df.head()

fig, axes = plt.subplots(3, 1, figsize=(14, 10))

# Prix de cl√¥ture
axes[0].plot(df.index, df['PX_LAST'], linewidth=1.5, color='#2563eb')
axes[0].set_title('Prix de Cl√¥ture ASML', fontsize=14, fontweight='bold')
axes[0].set_ylabel('Prix ($)')
axes[0].grid(True, alpha=0.3)

# Rendements
axes[1].plot(df.index, df['Returns'], linewidth=0.8, color='#059669')
axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
axes[1].set_title('Rendements Logarithmiques (%)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('Rendement (%)')
axes[1].grid(True, alpha=0.3)

# Distribution des rendements
axes[2].hist(df['Returns'], bins=50, edgecolor='black', alpha=0.7, color='#7c3aed')
axes[2].set_title('Distribution des Rendements', fontsize=14, fontweight='bold')
axes[2].set_xlabel('Rendement (%)')
axes[2].set_ylabel('Fr√©quence')
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Test de normalit√©
from scipy import stats
jb_stat, jb_pvalue = stats.jarque_bera(df['Returns'].dropna())
print(f"\nüìâ Test de Jarque-Bera (normalit√©):")
print(f"  - Statistique: {jb_stat:.4f}")
print(f"  - P-value: {jb_pvalue:.6f}")
print(f"  - Les rendements sont {'NON normaux' if jb_pvalue < 0.05 else 'normaux'}")

print("\n" + "="*70)
print("üî¨ MOD√àLE GARCH(1,1) - TRAIN/TEST SPLIT")
print("="*70)

# S√©paration train/test (80/20)
train_size = int(len(df) * 0.8)
train_data = df['Returns'].iloc[:train_size]
test_data = df['Returns'].iloc[train_size:]

print(f"\nüìä Taille des ensembles:")
print(f"  - Train: {len(train_data)} observations ({len(train_data)/len(df)*100:.1f}%)")
print(f"  - Test: {len(test_data)} observations ({len(test_data)/len(df)*100:.1f}%)")

# Estimation du mod√®le GARCH(1,1) sur le train set
model_train = arch_model(train_data, vol='Garch', p=1, q=1, dist='t')
results_train = model_train.fit(disp='off')

print(f"\nüìà R√©sultats du mod√®le GARCH(1,1):")
print(results_train.summary())

# Pr√©dictions sur le test set
forecasts = []
for i in range(len(test_data)):
    # Re-estimation avec donn√©es cumulatives
    temp_data = df['Returns'].iloc[:train_size + i]
    temp_model = arch_model(temp_data, vol='Garch', p=1, q=1, dist='t')
    temp_result = temp_model.fit(disp='off')
    forecast = temp_result.forecast(horizon=1)
    forecasts.append(np.sqrt(forecast.variance.values[-1, 0]))

forecasts = np.array(forecasts)

# Volatilit√© r√©alis√©e (rolling window de 20 jours)
realized_vol = test_data.rolling(window=20).std()

# M√©triques de performance
valid_idx = ~np.isnan(realized_vol)
rmse = np.sqrt(mean_squared_error(realized_vol[valid_idx], forecasts[valid_idx]))
mae = mean_absolute_error(realized_vol[valid_idx], forecasts[valid_idx])

print(f"\nüìä Performance sur le Test Set:")
print(f"  - RMSE: {rmse:.4f}%")
print(f"  - MAE: {mae:.4f}%")

# Visualisation des pr√©dictions
fig, ax = plt.subplots(figsize=(14, 6))
ax.plot(test_data.index, realized_vol, label='Volatilit√© R√©alis√©e', linewidth=2, color='#059669')
ax.plot(test_data.index, forecasts, label='Pr√©dictions GARCH', linewidth=2, color='#dc2626', linestyle='--')
ax.set_title('GARCH(1,1) - Pr√©dictions vs Volatilit√© R√©alis√©e', fontsize=14, fontweight='bold')
ax.set_ylabel('Volatilit√© (%)')
ax.set_xlabel('Date')
ax.legend()
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("\n" + "="*70)
print("üîÑ ANALYSE AVEC ROLLING WINDOW")
print("="*70)

window_size = 500  # Taille de la fen√™tre
step_size = 50     # Pas de progression

rolling_predictions = []
rolling_realized = []
rolling_dates = []

print(f"\n‚öôÔ∏è  Param√®tres:")
print(f"  - Taille de fen√™tre: {window_size} jours")
print(f"  - Pas: {step_size} jours")

for i in range(window_size, len(df), step_size):
    # Donn√©es pour la fen√™tre actuelle
    window_data = df['Returns'].iloc[i-window_size:i]

    # Estimation GARCH
    try:
        model_window = arch_model(window_data, vol='Garch', p=1, q=1, dist='t')
        result_window = model_window.fit(disp='off')

        # Pr√©diction 1 pas en avant
        forecast = result_window.forecast(horizon=1)
        pred_vol = np.sqrt(forecast.variance.values[-1, 0])

        # Volatilit√© r√©alis√©e suivante (20 jours)
        if i + 20 <= len(df):
            realized = df['Returns'].iloc[i:i+20].std()
        else:
            realized = df['Returns'].iloc[i:].std()

        rolling_predictions.append(pred_vol)
        rolling_realized.append(realized)
        rolling_dates.append(df.index[i])
    except:
        continue

rolling_predictions = np.array(rolling_predictions)
rolling_realized = np.array(rolling_realized)

# M√©triques rolling window
rmse_rolling = np.sqrt(mean_squared_error(rolling_realized, rolling_predictions))
mae_rolling = mean_absolute_error(rolling_realized, rolling_predictions)

print(f"\nüìä Performance Rolling Window:")
print(f"  - RMSE: {rmse_rolling:.4f}%")
print(f"  - MAE: {mae_rolling:.4f}%")
print(f"  - Nombre de fen√™tres: {len(rolling_predictions)}")

# Visualisation rolling window
fig, axes = plt.subplots(2, 1, figsize=(14, 10))

# Pr√©dictions vs R√©alis√©
axes[0].plot(rolling_dates, rolling_realized, label='Volatilit√© R√©alis√©e',
             linewidth=2, color='#059669', marker='o', markersize=4)
axes[0].plot(rolling_dates, rolling_predictions, label='Pr√©dictions GARCH',
             linewidth=2, color='#dc2626', linestyle='--', marker='s', markersize=4)
axes[0].set_title('Rolling Window - Pr√©dictions vs Volatilit√© R√©alis√©e',
                  fontsize=14, fontweight='bold')
axes[0].set_ylabel('Volatilit√© (%)')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Erreurs de pr√©diction
errors = rolling_predictions - rolling_realized
axes[1].bar(rolling_dates, errors, color=['#dc2626' if e > 0 else '#059669' for e in errors], alpha=0.6)
axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)
axes[1].set_title('Erreurs de Pr√©diction (Pr√©diction - R√©alis√©)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('Erreur (%)')
axes[1].set_xlabel('Date')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("\n" + "="*70)
print("üîç DIAGNOSTIC DU MOD√àLE")
print("="*70)

# Test sur les r√©sidus standardis√©s
std_resid = results_train.std_resid

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# R√©sidus standardis√©s
axes[0, 0].plot(std_resid, linewidth=0.8)
axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)
axes[0, 0].set_title('R√©sidus Standardis√©s', fontweight='bold')
axes[0, 0].set_ylabel('R√©sidu')
axes[0, 0].grid(True, alpha=0.3)

# Distribution des r√©sidus
axes[0, 1].hist(std_resid, bins=50, edgecolor='black', alpha=0.7, density=True)
x = np.linspace(-4, 4, 100)
axes[0, 1].plot(x, stats.norm.pdf(x), 'r-', linewidth=2, label='Normale(0,1)')
axes[0, 1].set_title('Distribution des R√©sidus Standardis√©s', fontweight='bold')
axes[0, 1].set_xlabel('R√©sidu')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# ACF des r√©sidus
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plot_acf(std_resid, lags=40, ax=axes[1, 0])
axes[1, 0].set_title('Autocorr√©lation des R√©sidus', fontweight='bold')

# ACF des r√©sidus au carr√©
plot_acf(std_resid**2, lags=40, ax=axes[1, 1])
axes[1, 1].set_title('Autocorr√©lation des R√©sidus¬≤', fontweight='bold')

plt.tight_layout()
plt.show()

# Tests statistiques
print(f"\nüìä Tests sur les r√©sidus:")
jb_stat_resid, jb_pvalue_resid = stats.jarque_bera(std_resid.dropna())
print(f"  - Jarque-Bera: stat={jb_stat_resid:.4f}, p-value={jb_pvalue_resid:.6f}")

print("\n" + "="*70)
print("üìã R√âSUM√â FINAL")
print("="*70)

print(f"\nüéØ Param√®tres du mod√®le GARCH(1,1):")
print(f"  - Omega (œâ): {results_train.params['omega']:.6f}")
print(f"  - Alpha (Œ±): {results_train.params['alpha[1]']:.6f}")
print(f"  - Beta (Œ≤): {results_train.params['beta[1]']:.6f}")
print(f"  - Persistance (Œ±+Œ≤): {results_train.params['alpha[1]'] + results_train.params['beta[1]']:.6f}")

print(f"\nüìä Performance:")
print(f"  - Train/Test RMSE: {rmse:.4f}%")
print(f"  - Train/Test MAE: {mae:.4f}%")
print(f"  - Rolling Window RMSE: {rmse_rolling:.4f}%")
print(f"  - Rolling Window MAE: {mae_rolling:.4f}%")

print("\n‚úÖ Analyse termin√©e!")