# -*- coding: utf-8 -*-
"""DLinear test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yivotpOgsq_QqAJzkof4LTL6Zx7Z3bgh
"""

!pip install yfinance torch numpy pandas matplotlib scikit-learn -q

import warnings, math
warnings.filterwarnings("ignore")

import yfinance as yf
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

TICKER = "GOOGL"     # tu peux mettre "GOOG" si tu préfères
PERIOD = "5y"        # 1y, 5y, 10y, max...
INTERVAL = "1d"      # 1d, 1wk, 1mo...

raw = yf.download(TICKER, period=PERIOD, interval=INTERVAL, auto_adjust=True)
if raw.empty:
    raise RuntimeError("Téléchargement vide. Essaie un autre ticker ou une autre période.")
df = raw[["Close"]].dropna().rename(columns={"Close":"price"})
df.head()

series = df["price"].values.astype(float)

# Split temporel (pas de mélange train/test)
train_ratio = 0.8
split_idx = int(len(series) * train_ratio)

train_vals = series[:split_idx]
test_vals  = series[split_idx:]

scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_vals.reshape(-1,1)).flatten()
# On transforme tout (train + test) avec le scaler du train (pour éviter la fuite d’info)
series_scaled = np.concatenate([
    train_scaled,
    scaler.transform(test_vals.reshape(-1,1)).flatten()
])

def create_sequences(arr, window, horizon=1):
    """
    arr : 1D array (série normalisée)
    window : taille de la fenêtre passée (input_length)
    horizon : nombre de pas à prédire (ici 1 = next-day close)
    """
    X, y = [], []
    for i in range(len(arr) - window - horizon + 1):
        X.append(arr[i:i+window])
        y.append(arr[i+window:i+window+horizon])
    return np.array(X), np.array(y).squeeze()

window_size = 60   # ~ 3 mois de trading
horizon = 1       # prévision à 1 jour (one-step ahead)

X_all, y_all = create_sequences(series_scaled, window_size, horizon)
aligned_split = split_idx - window_size
if aligned_split <= 0:
    raise RuntimeError("Fenêtre trop grande par rapport à la taille du train. Réduis window_size.")

X_train, y_train = X_all[:aligned_split], y_all[:aligned_split]
X_test,  y_test  = X_all[aligned_split:], y_all[aligned_split:]

X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32)
X_test  = torch.tensor(X_test,  dtype=torch.float32)
y_test  = torch.tensor(y_test,  dtype=torch.float32)

class DLinear(nn.Module):
    """
    Version simple: deux projections linéaires parallèles
    (on laisse le modèle "apprendre" une tendance et une saisonnalité implicites).
    """
    def __init__(self, input_size):
        super().__init__()
        self.trend_linear  = nn.Linear(input_size, 1)
        self.season_linear = nn.Linear(input_size, 1)

    def forward(self, x):
        # x: (batch, input_size)
        t = self.trend_linear(x)     # (batch, 1)
        s = self.season_linear(x)    # (batch, 1)
        return (t + s).squeeze(1)    # (batch,)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DLinear(input_size=window_size).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.MSELoss()

X_train_d = X_train.to(device)
y_train_d = y_train.to(device)
X_test_d  = X_test.to(device)
y_test_d  = y_test.to(device)

epochs = 300
train_losses = []
test_losses  = []

for epoch in range(1, epochs+1):
    # train
    model.train()
    optimizer.zero_grad()
    pred = model(X_train_d)
    loss = criterion(pred, y_train_d)
    loss.backward()
    optimizer.step()
    train_losses.append(loss.item())

    # validation
    model.eval()
    with torch.no_grad():
        val_pred = model(X_test_d)
        val_loss = criterion(val_pred, y_test_d).item()
        test_losses.append(val_loss)

    if epoch % 50 == 0:
        print(f"Epoch {epoch:3d}/{epochs} | Train {loss.item():.6f} | Test {val_loss:.6f}")

model.eval()
with torch.no_grad():
    y_hat_test_scaled = model(X_test_d).cpu().numpy()

# Inversion de l'échelle vers les prix
y_hat_test = scaler.inverse_transform(y_hat_test_scaled.reshape(-1,1)).flatten()
y_true_test = scaler.inverse_transform(y_test.cpu().numpy().reshape(-1,1)).flatten()

mae  = mean_absolute_error(y_true_test, y_hat_test)
rmse = math.sqrt(mean_squared_error(y_true_test, y_hat_test))
mape = np.mean(np.abs((y_true_test - y_hat_test) / (y_true_test + 1e-8))) * 100

print(f"\n✅ Résultats DLinear sur {TICKER} ({PERIOD}, {INTERVAL})")
print(f"MAE  : {mae:.4f}")
print(f"RMSE : {rmse:.4f}")
print(f"MAPE : {mape:.2f}%")

# Courbe de la perte
plt.figure(figsize=(9,4))
plt.plot(train_losses, label="Train MSE")
plt.plot(test_losses,  label="Test MSE")
plt.title("Courbes de perte")
plt.legend(); plt.tight_layout(); plt.show()

# Trajectoire test : vrai vs prédit (alignée temporellement)
plt.figure(figsize=(11,4))
plt.plot(y_true_test, label="Vrai (prix)")
plt.plot(y_hat_test,  label="Prévision (prix)")
plt.title(f"{TICKER} - Test set: vrai vs prédit (DLinear)")
plt.legend(); plt.tight_layout(); plt.show()

def recursive_forecast_last_k(model, series_scaled, window, k=5):
    """
    Prévision multi-pas récursive à partir de la fin de la série.
    On utilise la dernière fenêtre réelle, puis on réinjecte nos prédictions.
    """
    model.eval()
    buf = series_scaled.copy()
    preds_scaled = []
    with torch.no_grad():
        cur_window = buf[-window:].astype(np.float32)  # dernière fenêtre
        for _ in range(k):
            x = torch.tensor(cur_window, dtype=torch.float32).unsqueeze(0).to(device)
            y_hat = model(x).cpu().numpy().item()
            preds_scaled.append(y_hat)
            # on décale la fenêtre en ajoutant la prédiction
            cur_window = np.roll(cur_window, -1)
            cur_window[-1] = y_hat
    return np.array(preds_scaled)

k_days = 5
preds_next_scaled = recursive_forecast_last_k(model, series_scaled, window_size, k=k_days)
preds_next = scaler.inverse_transform(preds_next_scaled.reshape(-1,1)).flatten()

print(f"\nPrévisions récursives sur les {k_days} prochains jours (prix):")
for i, v in enumerate(preds_next, 1):
    print(f"J+{i}: {v:.2f}")

