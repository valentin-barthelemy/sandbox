# -*- coding: utf-8 -*-
"""Copie de Projet groupe portfolio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vmgI3ztGr7fvAvsjIc7-JvwER_u7ME3H
"""

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.optimize as sco

"""# En imaginant que le taux sans risque est donné sur le ticker GOVT"""

tickers_portfolio = ['COP', 'ADBE', 'COST','HD', 'JPM', 'LMT','MDT', 'NEE','PLD', 'V', 'VRTX', 'VZ']
benchmark = ['^GSPC']
risk_free = ['^IRX']
tickers = tickers_portfolio + benchmark + risk_free
data = yf.download(tickers, start='2019-06-19', end='2025-09-30',interval = '1d')['Close']
data = data[tickers]
colnames = tickers_portfolio + ["SPX", "Risk Free"]
data.columns = colnames
data.head()

projet = data.copy()

projet["Risk Free"] = projet["Risk Free"] / 100
projet["Risk Free"] = (1 + projet["Risk Free"]) ** (1/252) - 1

returns = (projet.drop(columns="Risk Free") - projet.drop(columns="Risk Free").shift(1)) / projet.drop(columns="Risk Free").shift(1)
mean_returns = returns.mean()
volatility = returns.std()
risk_free_mean = projet["Risk Free"].mean()
risk_premium = mean_returns - risk_free_mean

#returns = np.log(projet.drop(columns="Risk Free") / projet.drop(columns="Risk Free").shift(1))
#mean_returns = returns.mean()
#volatility = returns.std()
#risk_free_mean = projet["Risk Free"].mean()
#risk_premium = mean_returns - risk_free_mean

metrics = pd.DataFrame({
    'Mean Return': mean_returns,
    'Volatility': volatility,
    'Risk Premium': risk_premium
})

metrics

def annual_metrics (metrics_df):
  mean_ann_returns = metrics_df["Mean Return"] * 252
  vol_ann = metrics_df["Volatility"] * np.sqrt(252)
  prem_ann = metrics_df["Risk Premium"] * 252

  sharpe = prem_ann / vol_ann

  annual_df = pd.DataFrame({
    "Mean Return (Annual, in %)": mean_ann_returns*100,
    "Volatility (Annual, in %)": vol_ann * 100,
    "Risk Premium (Annual, in %)": prem_ann * 100,
    "Sharpe Ratio": sharpe
  })
  return annual_df

annual_metrics(metrics)

plt.figure(figsize=(10, 6))
for ticker in tickers_portfolio:
    plt.plot(projet.index, projet[ticker], label=ticker)
plt.title('Portfolio Value Over Time')
plt.xlabel('Date')
plt.ylabel('Value')
plt.grid(True)
plt.legend()
plt.show()

stock_returns = returns[tickers_portfolio]
mean_stock_returns = stock_returns.mean()
cov_stock_matrix = stock_returns.cov() * 252

sns.pairplot(stock_returns)
plt.show()

corr_matrix= stock_returns.corr()
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot = True, cmap='coolwarm', fmt=".2f",)
plt.title('Correlation Matrix')
plt.show()

plt.figure(figsize=(6, 4))
sns.clustermap(corr_matrix, annot = True, cmap='coolwarm', fmt=".2f",)
plt.title('Cluster Map')
plt.show()

all_returns = projet.pct_change().dropna()
stock_returns_clean = all_returns[tickers_portfolio]
mean_returns_daily = stock_returns_clean.mean()
cov_matrix_annual = stock_returns_clean.cov() * 252
rf_rate_daily = projet["Risk Free"].mean()

def portfolio_annualised_performance(weights, mean_returns, cov_matrix):
    returns = np.sum(mean_returns * weights) * 252
    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    return std, returns

def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):

    p_vol, p_ret = portfolio_annualised_performance(weights, mean_returns, cov_matrix)
    return -(p_ret - risk_free_rate * 252) / p_vol

num_assets = len(tickers_portfolio)
args = (mean_returns_daily, cov_matrix_annual, rf_rate_daily)

constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
bounds = tuple((0.0, 1.0) for asset in range(num_assets))
init_guess = num_assets * [1. / num_assets,]

result = sco.minimize(neg_sharpe_ratio, init_guess, args=args,
                      method='SLSQP', bounds=bounds, constraints=constraints)

optimal_weights = result.x
opt_vol, opt_ret = portfolio_annualised_performance(optimal_weights, mean_returns_daily, cov_matrix_annual)

print("-" * 50)
print("RÉSULTATS DE L'OPTIMISATION (PORTFOLIO MAX SHARPE)")
print("-" * 50)
print(f"Rendement Annualisé Attendu : {opt_ret:.2%}")
print(f"Volatilité Annualisée       : {opt_vol:.2%}")
print(f"Ratio de Sharpe             : {(opt_ret - rf_rate_daily*252) / opt_vol:.2f}")
print("-" * 50)

allocation_df = pd.DataFrame({
    'Ticker': tickers_portfolio,
    'Poids Optimaux (%)': np.round(optimal_weights * 100, 2)
})

allocation_df = allocation_df.sort_values(by='Poids Optimaux (%)', ascending=False)
print(allocation_df)

plt.figure(figsize=(12, 6))
plt.bar(allocation_df['Ticker'], allocation_df['Poids Optimaux (%)'], color='skyblue')
plt.title('Allocation Optimale suggérée par le Solver')
plt.ylabel('Poids (%)')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

spx_returns = projet["SPX"].pct_change().dropna()

risk_free_rate_ann = projet["Risk Free"].mean() * 252
market_return_ann = spx_returns.mean() * 252
market_premium = market_return_ann - risk_free_rate_ann

betas = {}
capm_expected_returns = {}

print("\n" + "=" * 70)
print(f"S10 METRICS : BETA & CAPM (Données complètes jusqu'au 30/09/2025)")
print(f"Market Return (SPX): {market_return_ann:.2%} | Risk Free Rate: {risk_free_rate_ann:.2%}")
print("=" * 70)
print(f"{'Ticker':<10} | {'Beta':<10} | {'CAPM Return':<15} | {'Mean Hist Return':<15}")
print("-" * 70)

for ticker in tickers_portfolio:
    cov_mat = np.cov(stock_returns_clean[ticker], spx_returns)
    beta = cov_mat[0, 1] / cov_mat[1, 1]
    betas[ticker] = beta
    capm_ret = risk_free_rate_ann + beta * market_premium
    capm_expected_returns[ticker] = capm_ret
    hist_ret = stock_returns_clean[ticker].mean() * 252

    print(f"{ticker:<10} | {beta:.4f}     | {capm_ret:.2%}        | {hist_ret:.2%}")

print("-" * 70)

def portfolio_volatility(weights, mean_returns, cov_matrix):
    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))

target_returns = np.linspace(mean_returns_daily.min() * 252, mean_returns_daily.max() * 252, 50)
efficient_volatilities = []

for target in target_returns:
    constraints_eff = (
        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
        {'type': 'eq', 'fun': lambda x: np.sum(x * mean_returns_daily) * 252 - target}
    )

    res = sco.minimize(portfolio_volatility, init_guess, args=(mean_returns_daily, cov_matrix_annual),
                       method='SLSQP', bounds=bounds, constraints=constraints_eff)

    efficient_volatilities.append(res.fun)

plt.figure(figsize=(12, 8))

plt.plot(efficient_volatilities, target_returns, 'b--', linewidth=2, label='Frontière Efficiente')

plt.scatter(np.sqrt(np.diag(cov_matrix_annual)), mean_returns_daily * 252,
            color='red', s=50, label='Actions (Unitaires)')

for i, txt in enumerate(tickers_portfolio):
    plt.annotate(txt,
                 (np.sqrt(cov_matrix_annual.iloc[i,i]), mean_returns_daily.iloc[i] * 252),
                 xytext=(5,5), textcoords='offset points')

spx_vol = spx_returns.std() * np.sqrt(252)
spx_ret = spx_returns.mean() * 252
plt.scatter(spx_vol, spx_ret, color='green', s=150, marker='*', label='SPX Benchmark')

plt.scatter(opt_vol, opt_ret, color='gold', s=250, marker='*', edgecolors='black', zorder=10, label='Ton Portefeuille Optimal')

plt.title('Efficient Frontier & CAPM Analysis (Full Period)')
plt.xlabel('Volatilité Annualisée (Risque)')
plt.ylabel('Rendement Attendu Annualisé')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

